{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree Species Classification in Orthoimages of Brandenburg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL import Image\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from torch import permute, nan_to_num\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor, Resize\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from trees_brandenburg import preprocess, plotting\n",
    "from trees_brandenburg.modelling import train, inference\n",
    "from trees_brandenburg.external import transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview\n",
    "\n",
    "The goal of this notebook is develop a CNN from which can classify different tree species in orthoimages. The data used are orthoimages from Brandenburg from different years and seasons. For more detail about the images, see [here](https://geobroker.geobasis-bb.de/gbss.php?MODE=GetProductInformation&PRODUCTID=253b7d3d-6b42-47dc-b127-682de078b7ae).\n",
    "All images with a resolution of 20cm were downloaded and further processed into final image tiles of 100px by 100px.\n",
    "\n",
    "The table below shows the number of training samples per tree species. The most dominant species by is the *Pinus sylvestris*, followed by *Alnus rubra* and *Quercus robur*. The dataset contains 33 different species. In a first effort however, we're only trying to clssify the five most prominent ones.\n",
    "\n",
    "To make our lives easier, the raw data (`data/raw`) is renamed and moved into a different folder (`data/processed`).\n",
    "\n",
    "| **Species** | **Number of training samples** |\n",
    "|:-----------:|--------------------------------|\n",
    "| GKI         | 201633                         |\n",
    "| RER         | 5876                           |\n",
    "| SEI         | 2834                           |\n",
    "| GBI         | 2482                           |\n",
    "| TEI         | 2169                           |\n",
    "| GDG         | 1893                           |\n",
    "| RBU         | 1741                           |\n",
    "| ELA         | 1524                           |\n",
    "| REI         | 1305                           |\n",
    "| GFI         | 1186                           |\n",
    "| PAS         | 599                            |\n",
    "| RO          | 435                            |\n",
    "| EI          | 315                            |\n",
    "| BPA         | 217                            |\n",
    "| BAH         | 191                            |\n",
    "| JLA         | 169                            |\n",
    "| WKI         | 145                            |\n",
    "| WEB         | 114                            |\n",
    "| SKI         | 101                            |\n",
    "| WLI         | 86                             |\n",
    "| KTA         | 78                             |\n",
    "| SAH         | 71                             |\n",
    "| AS          | 59                             |\n",
    "| HBU         | 58                             |\n",
    "| WLS         | 34                             |\n",
    "| HLS         | 31                             |\n",
    "| WER         | 26                             |\n",
    "| GES         | 25                             |\n",
    "| STK         | 22                             |\n",
    "| BFI         | 17                             |\n",
    "| SFI         | 13                             |\n",
    "| EIS         | 13                             |\n",
    "| HPA         | 12                             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_subset: List[str] = [\"GKI\", \"RER\", \"SEI\", \"GBI\", \"TEI\"]\n",
    "src: Path = Path(\"../data/raw\")\n",
    "subset: Path = Path(\"../data/processed/imgs\")\n",
    "preprocess.generate_subset(src, subset, class_subset)\n",
    "\n",
    "metadata = pd.read_csv(\"../data/processed/sensing-dates.csv\")\n",
    "metadata.query(\"month >= 4 and month <= 10\")\n",
    "\n",
    "data = preprocess.generate_data_overview(subset)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we exclude all images that were not taken between april and october. We can see that quite a substantial amount of images is removed this way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Rows before filtering: {data.shape[0]}\")\n",
    "data = preprocess.filter_image_df(data, metadata.tile)\n",
    "print(f\"Rows after filtering: {data.shape[0]}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this further reduces training data for now, we set apart 5% of the available data for testing at the end. When more training data is available, this should be increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_oud: pd.DataFrame = data.sample(frac=0.05)\n",
    "data = data.drop(hold_oud.index)\n",
    "hold_out = hold_oud.reset_index()\n",
    "data = data.reset_index()\n",
    "print(\"Final data:\")\n",
    "print(f\"\\t{data.shape[0]} images can be used for training/fine tuning\")\n",
    "print(f\"\\t{hold_out.shape[0]} will be used for final validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Trainig\n",
    "\n",
    "Define key-parameters for the training of the deep learning model. This is required early in the code as for example batch size is needed to define the DataLoader in the correct way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device: torch.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "batch_size: int = 1024\n",
    "validation_split: float = .3\n",
    "shuffle_dataset: bool = True\n",
    "random_seed: int = 42\n",
    "n_epochs: int = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data split and create data loaders that will allow you to load the data into the model training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size: int = len(data)\n",
    "indices: List[int] = list(range(dataset_size))\n",
    "split: int = int(math.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "training_sampler, validation_sampler = SubsetRandomSampler(indices[split:]), SubsetRandomSampler(indices[:split])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define data transformations and create a Pytorch dataset class instance. Do the transforms make sense when used for the fine-tuning procedure below? Actually not sure..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "dataset = train.TreeSpeciesClassificationDataset(data, transform)<"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Dataloader for the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=training_sampler, pin_memory=True if \"cuda\" in device.type else False, num_workers=10)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=validation_sampler, pin_memory=True if \"cuda\" in device.type else False, num_workers=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do some plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_labels: Dict[int, str] = data[[\"encoded_labels\", \"labels\"]].drop_duplicates(ignore_index=True).to_dict()[\"labels\"]\n",
    "fig, ax = plotting.plot_images(train_loader, reverse_labels, figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the model and set up our optimizer. Here, we also adjust the weights (not fully understood by me) to work with imbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = train.CNN()\n",
    "\n",
    "num_samples = np.empty((len(class_subset),))\n",
    "num_samples[data.encoded_labels.value_counts().index.values] = data.encoded_labels.value_counts().values\n",
    "weights = 1.0 / num_samples\n",
    "normalized_weights = weights / np.sum(weights) # norm to 1\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.from_numpy(normalized_weights).float())\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 10\n",
    "valid_loss_min = np.inf\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "total_step = len(train_loader)\n",
    "\n",
    "FINAL_MODEL_PATH: Path = Path(\"../data/processed\") / 'model_scripted.pt'\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total=0\n",
    "    print(f'Epoch {epoch}\\n')\n",
    "    for batch_idx, (data_, target_) in enumerate(train_loader):\n",
    "        optimizer.zero_grad() # zero the parameter gradients\n",
    "        # forward + backward + optimize\n",
    "        outputs = cnn_model(data_)\n",
    "        loss = criterion(outputs, target_.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        correct += train.accuracy(outputs, target_)\n",
    "        total += target_.size(0)\n",
    "        if (batch_idx) % 20 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch, n_epochs, batch_idx, total_step, loss.item()))\n",
    "    train_acc.append(100 * correct / total)\n",
    "    train_loss.append(running_loss/total_step)\n",
    "    print(f'\\ntrain loss: {np.mean(train_loss):.4f}, train acc: {(100 * correct / total):.4f}')\n",
    "    batch_loss = 0\n",
    "    total_t=0\n",
    "    correct_t=0\n",
    "    cnn_model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for data_t, target_t in validation_loader:\n",
    "            outputs_t = cnn_model(data_t)\n",
    "            loss_t = criterion(outputs_t, target_t.long())\n",
    "            batch_loss += loss_t.item()\n",
    "            _,pred_t = torch.max(outputs_t, dim=1)\n",
    "            correct_t += torch.sum(pred_t==target_t).item()\n",
    "            total_t += target_t.size(0)\n",
    "        val_acc.append(100 * correct_t / total_t)\n",
    "        val_loss.append(batch_loss/len(validation_loader))\n",
    "        network_learned = batch_loss < valid_loss_min  # FIXME is this correct?\n",
    "        print(f'validation loss: {np.mean(val_loss):.4f}, validation acc: {(100 * correct_t / total_t):.4f}\\n')\n",
    "        # Saving the best weight \n",
    "        if network_learned:\n",
    "            valid_loss_min = batch_loss\n",
    "            torch.save(cnn_model.state_dict(), Path(\"../data/processed\") / 'model_classification_tutorial.pt')\n",
    "            print('Detected network improvement, saving current model')\n",
    "    cnn_model.train()\n",
    "\n",
    "model_scripted = torch.jit.script(cnn_model)\n",
    "model_scripted.save(FINAL_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Training\n",
    "\n",
    "After we're done with the model trainin, let us plot both the training/validation loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.title(\"Train - Validation Loss\")\n",
    "plt.plot( train_loss, label='train')\n",
    "plt.plot( val_loss, label='validation')\n",
    "plt.xlabel('num_epochs', fontsize=12)\n",
    "plt.ylabel('loss', fontsize=12)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.title(\"Train - Validation Accuracy\")\n",
    "plt.plot(train_acc, label='train')\n",
    "plt.plot(val_acc, label='validation')\n",
    "plt.xlabel('num_epochs', fontsize=12)\n",
    "plt.ylabel('accuracy', fontsize=12)\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Validation\n",
    "\n",
    "Why exactly are we plotting the validation data here? Whatever..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.jit.load(FINAL_MODEL_PATH)\n",
    "model.eval()\n",
    "\n",
    "fig, ax = plotting.plot_validation(train_loader, model, reverse_labels, figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some first thoughts on the results\n",
    "\n",
    "The model trained above is a lot f things, but not good. The drastically decreasing validation accuracy can likely be contributed to overfitting[^1]. The training data is not that large for a deep learning problem set in addition to the data not being *clean*. For comparison, the MNIST dataset consists of 60000 training data and 10000 validation data for a much more simple problem set.\n",
    "\n",
    "Multiple pathways may lead to improvements:\n",
    "\n",
    "1. Simpler model architecture. The model would be able to learn less but could also be less prone to overfitting\n",
    "1. Stronger regularization would prevent overfitting\n",
    "1. Cleaner data\n",
    "1. More data\n",
    "1. Using apre-trained model\n",
    "\n",
    "\n",
    "\n",
    "Even though it's listed last above, I want set up a baseline (i.e. *learn* and predict the majority class at all times) and try out an already pre-trained model.\n",
    "\n",
    "## Base Line Prediction\n",
    "\n",
    "**TODO:** The accuracy metric is dependent on class distribution and thus problematic! Nonetheless, it's used as an accuracy metric here.\n",
    "\n",
    "[^1]: https://datascience.stackexchange.com/questions/47720/validation-loss-increases-and-validation-accuracy-decreases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_accuracy = np.sum(data[\"encoded_labels\"] == num_samples.argmax()) / data.shape[0]\n",
    "print(baseline_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained model\n",
    "\n",
    "Pytorch offers a plathora of pre-trained models. There won't be an exhaustive search for which model performs best on the given dataset here and I simply use a ResNet.\n",
    "\n",
    "A tutorial is provided [here](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html#finetuning-the-convnet). Note, that I don't employ a exponential learning rate decay and use the CrossEntropy and Adam-optimizer in accordance with their original instantiations above.\n",
    "\n",
    "> Something's not quite working. The GPU-utilization is rather low which indicates a bottleneck *somewhere*\n",
    "> \n",
    "> either in the model itself (rather unlikely)\n",
    "> or in the approach to load the data (more likely)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_weights = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "inference_preprocess = models.ResNet18_Weights.DEFAULT.transforms()\n",
    "\n",
    "original_features = res_weights.fc.in_features\n",
    "res_weights.fc = nn.Linear(original_features, len(num_samples))\n",
    "res_weights = res_weights.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.from_numpy(normalized_weights).float().to(device))\n",
    "optimizer = optim.Adam(res_weights.parameters(), lr=0.0001)\n",
    "\n",
    "dataloaders = {\n",
    "    \"train\": train_loader,\n",
    "    \"val\": validation_loader\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    \"train\": len(training_sampler),\n",
    "    \"val\": len(validation_sampler)\n",
    "}\n",
    "\n",
    "model_ft = transfer.train_model(res_weights, dataloaders, dataset_sizes, criterion, optimizer, device, None, num_epochs=3)\n",
    "\n",
    "model_scripted = torch.jit.script(model_ft)\n",
    "model_scripted.save(Path(\"../models\") / \"fine-tunned-resnet18.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO access class predictions differently (see blow or `torch.max(model_ft(images), 1).indices == labels`)\n",
    "model_ft = torch.jit.load(Path(\"../models\") / \"fine-tunned-resnet18.pt\")\n",
    "#fig, ax = plotting.plot_ft_validation(validation_loader, model_ft, reverse_labels, figsize=(15, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the newly-trained model perform with completely unseen data?\n",
    "Note, that the original transformations of the ResNet are applied here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_out_dataset = train.TreeSpeciesClassificationDataset(hold_out, inference_preprocess)\n",
    "hold_out_loader = torch.utils.data.DataLoader(hold_out_dataset, batch_size=64, pin_memory=True if \"cuda\" in device.type else False, num_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_correct = torch.tensor(0).to(device)\n",
    "for images, labels in hold_out_loader:\n",
    "    with torch.inference_mode():\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        number_correct += torch.sum(torch.argmax(model_ft(images), 1) == labels)\n",
    "\n",
    "print(number_correct / len(hold_out_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm, ok so with just two epochs of fine-tuning, we achieven an overall accuracy of 27% - drastically lower compared to training accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the Hyperparameters\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting into the area\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- other interesting idea: include nir channel and ditch green or blue channel!\n",
    "- What about weighted frequency or better yet, a frequency independent accuracy metric?!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trees-brandenburg-i6a-qrbk-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
